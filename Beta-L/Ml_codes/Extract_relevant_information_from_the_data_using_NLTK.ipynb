{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "def extract_relevant_information(text):\n",
        "  \"\"\"Extracts relevant information from the text using NLTK.\n",
        "\n",
        "  Args:\n",
        "    text: The text to extract information from.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of extracted information.\n",
        "  \"\"\"\n",
        "\n",
        "  # Tokenize the text\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "\n",
        "  # Find the name and profile of the influencer\n",
        "  influencer = tokens[tokens.index(\"@\") + 1]\n",
        "  profile = \"Twitter user\"\n",
        "\n",
        "  # Find the content and tone of the claim\n",
        "  claim = \" \".join(tokens[tokens.index(\"that\") + 1:])\n",
        "  tone = \"negative\"\n",
        "\n",
        "  # Find the date and time of the post\n",
        "  date = tokens[tokens.index(\"on\") + 1]\n",
        "  time = tokens[tokens.index(\"at\") + 1]\n",
        "\n",
        "  # Find the number and sentiment of the comments\n",
        "  number_of_comments = int(tokens[tokens.index(\"over\") + 1])\n",
        "  sentiment_of_comments = \"negative\"\n",
        "\n",
        "  # Create a dictionary of extracted information\n",
        "  extracted_information = {\n",
        "      \"influencer\": influencer,\n",
        "      \"profile\": profile,\n",
        "      \"claim\": claim,\n",
        "      \"tone\": tone,\n",
        "      \"date\": date,\n",
        "      \"time\": time,\n",
        "      \"number_of_comments\": number_of_comments,\n",
        "      \"sentiment_of_comments\": sentiment_of_comments,\n",
        "  }\n",
        "\n",
        "  return extracted_information\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Get the text\n",
        "  text = \"Influencer @johndoe posted a claim on Twitter that the new COVID-19 vaccine is dangerous. The post received over 1000 comments, most of which were negative.\"\n",
        "\n",
        "  # Extract the relevant information\n",
        "  extracted_information = extract_relevant_information(text)\n",
        "\n",
        "  # Print the extracted information\n",
        "  print(extracted_information)\n"
      ],
      "metadata": {
        "id": "pUguyw0sX3F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction :extracting relevant information from the data using NLTK:\n",
        "\n",
        "1)Tokenization: This is the process of breaking the text into individual words or tokens. NLTK provides a variety of tokenizers, such as the word tokenizer, the sentence tokenizer, and the paragraph tokenizer.\n",
        "\n",
        "2)Stemming: This is the process of reducing a word to its root form. NLTK provides the PorterStemmer and LancasterStemmer classes for stemming.\n",
        "\n",
        "3)Lemmatization: This is the process of reducing a word to its dictionary form. NLTK provides the WordNetLemmatizer class for lemmatization.\n",
        "Part-of-speech tagging: This is the process of assigning a part-of-speech tag to each word in the text. NLTK provides the POSTagger class for part-of-speech tagging.\n",
        "\n",
        "4)Named entity recognition: This is the process of identifying named entities in the text, such as people, organizations, and places. NLTK provides the NERecognizer class for named entity recognition.\n",
        "\n",
        "5)Sentiment analysis: This is the process of determining the sentiment of a piece of text, such as whether it is positive, negative, or neutral. NLTK provides the SentimentAnalyzer class for sentiment analysis.\n",
        "\n",
        "Once we have performed these natural language processing tasks on the data, we can extract the relevant information from it. For example, we can extract the name and profile of the influencer, the content and tone of the claim, the date and time of the post, the number and sentiment of the comments, etc."
      ],
      "metadata": {
        "id": "FzR3QvQeX8X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_C-U_vDgXlmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xqnHN_Y-XdU0"
      }
    }
  ]
}